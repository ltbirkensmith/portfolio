<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autonomous Self-Landing UAV - Liam Smith</title>

    <link rel="stylesheet" href="gallery.css">
    <script src="gallery.js" defer></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.6;
            color: #000;
            background: #fff;
        }
        
        .project-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 60px 20px;
        }
        
        .back-link {
            display: inline-block;
            color: #9BCBEB;
            text-decoration: none;
            margin-bottom: 30px;
            font-size: 16px;
        }
        
        .back-link:hover {
            color: #6BA3C3;
        }
        
        .project-header {
            margin-bottom: 40px;
        }
        
        .project-title {
            font-size: 42px;
            font-weight: 700;
            margin-bottom: 20px;
        }
        
        .project-subtitle {
            font-size: 20px;
            color: #666;
            margin-bottom: 30px;
        }
        
        .project-meta {
            display: flex;
            gap: 30px;
            flex-wrap: wrap;
            margin-bottom: 40px;
        }
        
        .meta-item {
            display: flex;
            flex-direction: column;
        }
        
        .meta-label {
            font-size: 12px;
            text-transform: uppercase;
            color: #666;
            margin-bottom: 5px;
            letter-spacing: 1px;
        }
        
        .meta-value {
            font-size: 16px;
            color: #000;
        }
        
        .content-section {
            margin-bottom: 40px;
        }
        
        .section-title {
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
            color: #000;
        }
        
        .section-text {
            font-size: 18px;
            line-height: 1.8;
            color: #333;
            margin-bottom: 20px;
        }
        
        .tech-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 30px;
        }
        
        .tech-tag {
            background: #9BCBEB;
            color: #fff;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
        }
        
        .achievements-list {
            list-style: none;
            margin-bottom: 30px;
        }
        
        .achievements-list li {
            padding-left: 30px;
            position: relative;
            margin-bottom: 15px;
            font-size: 18px;
            line-height: 1.6;
        }
        
        .achievements-list li:before {
            content: "→";
            position: absolute;
            left: 0;
            color: #9BCBEB;
            font-weight: bold;
        }
        
        .status-badge {
            display: inline-block;
            background: #fff3cd;
            color: #856404;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 20px;
        }
        
        @media (max-width: 768px) {
            .project-title {
                font-size: 32px;
            }
            
            .project-subtitle {
                font-size: 18px;
            }
            
            .section-title {
                font-size: 24px;
            }
            
            .section-text {
                font-size: 16px;
            }
        }
    </style>
</head>
<body>
    <div class="project-container">
        <a href="engineering.html" class="back-link">← Back to Engineering Portfolio</a>
        
        <div class="project-header">
            <h1 class="project-title">Autonomous Self-Landing UAV</h1>
            <p class="project-subtitle">Vision-Based Autonomous Landing System Using YOLO and Raspberry Pi</p>
        </div>
        
        <div class="project-meta">
            <div class="meta-item">
                <span class="meta-label">Type</span>
                <span class="meta-value">Personal Project</span>
            </div>
            <div class="meta-item">
                <span class="meta-label">Started</span>
                <span class="meta-value">Summer 2025</span>
            </div>
            <div class="meta-item">
                <span class="meta-label">Expected First Flight</span>
                <span class="meta-value">Summer 2026</span>
            </div>
            <div class="meta-item">
                <span class="meta-label">Status</span>
                <span class="meta-value">Development & Testing</span>
            </div>
        </div>
        
        <span class="status-badge">⚙️ Project In Progress</span>

         <!--Gallery photo-->
        <div class="project-gallery">
                <h2>Project Gallery</h2>
                <div class="gallery-grid">
                    
                    <div class="gallery-item">
                        <img src="Media/EPortfolio_Images/microg.jpg" alt="ASTROID CAD Model">
                        <div class="gallery-caption">
                            <p>Labelled diagram of the ASTROID device</p>
                        </div>
                    </div>
                    
                    <div class="gallery-item">
                        <img src="Media/Copy%20of%201F8A800B-C7A2-40DF-8F60-368BB8B28858.JPG">
                        <div class="gallery-caption">
                            <p>Me at the NBL control panel observing the test run-through along with the rest of CSI's team.</p>
                        </div>
                    </div>
                    
                    <div class="gallery-item">
                        <img src="Media/EPortfolio_Images/overshotmicrog.png" alt="Team Presentation at JSC">
                        <div class="gallery-caption">
                            <p>Photograph of ASTROID device after testing in the Lunar Simulant Lab</p>
                        </div>
                    </div>
                    
                    <div class="gallery-item">
                        <img src="Media/EPortfolio_Images/microg.jpg" alt="Regolith Sample Collection">
                        <div class="gallery-caption">
                            <p>Research poster for presentation</p>
                        </div>
                    </div>
                    
                    <div class="gallery-item">
                        <img src="Media/EPortfolio_Images/undershotmicrog.png" alt="3D Printed Components">
                        <div class="gallery-caption">
                            <p>SOLIDWORKS model showing ASTROID device functionality</p>
                        </div>
                    </div>

                    <div class="gallery-item">
                        <video controls loop>
                        <source src="Media/EPortfolio_Images/WhatsApp%20Video%202025-05-30%20at%2018.26.34%20(online-video-cutter.com).mp4" muted controls type="video/mp4">
                        Your browser does not support the video tag.
                        </video>
                        <div class="gallery-caption">
                            <p>Video showing ASTROID functionality, as tested by me</p>
                    </div>
                    
                </div>
            </div>
    
        
        <div class="content-section">
            <h2 class="section-title">General Overview</h2>
            <p class="section-text">
                This summer, I set out to build a model airplane capable of landing itself autonomously using only visual guidance and an ultrasonic distance sensor to measure ground-level altitude. My goal was to create a resilient system that could land from any configuration on a strip of land that can function as a runway.
            </p>
            <p class="section-text">
                This project represents the intersection of computer vision, machine learning, mechatronics, and aeronautical response. While I am still currently training my models and attempting to get better recognition and guidance as I try and resolve the legality of my plans, I'm excited about where this project might continue. Additionally, this was perhaps the first project where I've used AI to generate the framework of my code base.
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Technologies and Skills Used</h2>
            <div class="tech-tags">
                <span class="tech-tag">YOLO (You Only Look Once)</span>
                <span class="tech-tag">Raspberry Pi</span>
                <span class="tech-tag">ESP32 Flight Controller</span>
                <span class="tech-tag">Arduino</span>
                <span class="tech-tag">Computer Vision</span>
                <span class="tech-tag">Real-Time Processing</span>
                <span class="tech-tag">Python</span>
                <span class="tech-tag">Machine Learning</span>
                <span class="tech-tag">Embedded Systems</span>
            </div>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">System Architecture</h2>
            <p class="section-text">
                <strong>Vision System (Raspberry Pi + YOLO):</strong> The Raspberry Pi processes visual signals and determines long-term flight commands. It runs a customized YOLO visual recognition model with Kalman filters paired with intertial navigationtrained to identify runways, calculate distances, and detect obstacles reliably. The YOLO model processes video frames in real-time to extract critical landing information including runway orientation, distance, and approach angle.
            </p>
            <p class="section-text">
                <strong>Primary Flight Controller (ESP32):</strong> The ESP32 microcontroller acts as the primary flight controller, receiving commands from the Raspberry Pi and translating them into servo movements and throttle adjustments. Additionally, it handles flight stabilization and 
            </p>
            <p class="section-text">
                <strong>Safety Backup (Arduino):</strong> An Arduino microcontroller serves as a conduit for signals that can enable or disable transmitter and Pi-issues signals. It provides basic stabilization and emergency landing capabilities, ensuring the aircraft can be recovered even if the vision or ESP32 systems malfunction.
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Development Progress</h2>
            <ul class="achievements-list">
                <li>Programmed initial YOLO visual recognition model for runway detection and identification</li>
                <li>Integrated Raspberry Pi hardware with camera system for real-time image capture</li>
                <li>Configured ESP32 as flight controller with servo and throttle control capabilities</li>
                <li>Conducted testing with real runway images to validate accuracy and object detection</li>
                <li>Created mockup integration of system components within test aircraft for CG and mass purposes</li>
            </ul>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Current Challenges</h2>
            <p class="section-text">
                <strong>Processing Speed Optimization:</strong> The primary challenge is refining the YOLO model and decision framework to operate on a timescale workable for high-speed flight. Model airplanes approach and land at speeds of 20-40 mph, requiring processing and decision cycles measured in milliseconds. Current work focuses on model optimization, frame rate management, and predictive algorithms that can anticipate required control inputs.
            </p>
            <p class="section-text">
                <strong>Real-Time Decision Making:</strong> Translating vision data into flight control commands requires sophisticated decision algorithms that can handle varying lighting conditions, wind effects, and unexpected obstacles.
            </p>
            <p class="section-text">
                <strong>Hardware Integration:</strong> Integrating multiple processors (Raspberry Pi, ESP32, Arduino) with sensors, servos, and power systems within the confined space of the model I am using (A Cirrus SR22 1.4m scale model). Weight distribution and power management are sticking points.
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">YOLO Visual Recognition Model</h2>
            <p class="section-text">
                YOLO (You Only Look Once) is a state-of-the-art real-time object detection system. Unlike traditional computer vision approaches that require multiple passes over an image, YOLO analyzes the entire image in a single pass, making it ideal for applications requiring fast, real-time performance like autonomous flight.
            </p>
            <p class="section-text">
                <strong>Training Process:</strong> The model is being trained on a custom dataset of runway images captured from various angles, distances, and lighting conditions. Training includes normal runways, emergency landing strips, and various ground markings to ensure robust detection capability across different scenarios.
            </p>
            <p class="section-text">
                <strong>Output Data:</strong> The trained model outputs runway bounding boxes, confidence scores, distance estimates, and orientation angles. This data feeds into the decision framework which calculates required heading adjustments, descent rates, and throttle settings for a safe landing approach.
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Decision Framework Architecture</h2>
            <ul class="achievements-list">
                <li>State machine architecture tracking flight phases: search, approach, final, flare, touchdown</li>
                <li>PID controllers for stable heading and altitude control integrated via ArduPilot</li>
                <li>Kalman filtering to smooth noisy vision data and predict future positions</li>
                <li>Risk assessment algorithms that evaluate landing safety and can trigger go-around</li>
                <li>Wind estimation using ground speed calculations and drift compensation</li>
                <li>Energy management ensuring sufficient altitude and airspeed throughout approach</li>
                <li>Failsafe logic monitoring system health and triggering backup systems if needed</li>
            </ul>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Testing Methodology</h2>
            <p class="section-text">
                <strong>Benchtop Testing:</strong> Currently testing the vision system and decision framework using pre-recorded runway footage and simulated flight data. This allows rapid iteration without risk to aircraft hardware. Accuracy and response time measurements inform optimization efforts.
            </p>
            <p class="section-text">
                <strong>Ground Testing:</strong> Next, I will likely test it in the air with manual landing and record system behavior and compare it to my own behavior.
            </p>
            <p class="section-text">
                <strong>Flight Testing Plan:</strong> Full flight testing will likely not happen due to legality issues of autonomous UAVs
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Skills Being Developed</h2>
            <ul class="achievements-list">
                <li>Machine learning model training and optimization for embedded systems</li>
                <li>Real-time computer vision programming and image processing</li>
                <li>Embedded systems integration with multiple microcontrollers</li>
                <li>Flight control algorithms and PID tuning</li>
                <li>Sensor fusion and state estimation techniques</li>
                <li>System architecture design for safety-critical applications</li>
                <li>Aerodynamic considerations for autonomous flight</li>
                <li>Systematic testing and debugging of complex integrated systems</li>
            </ul>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Timeline & Milestones</h2>
            <p class="section-text">
                <strong>Summer 2025:</strong> Project initiation, YOLO model development, hardware procurement and initial integration.
            </p>
            <p class="section-text">
                <strong>Fall 2025 - Spring 2026:</strong> Model training and optimization.
            </p>
            <p class="section-text">
                <strong>Summer 2026:</strong> Flight testing without control authority to measure performance in a real setting.
            </p>
            <p class="section-text">
                <strong>Expected Achievement:</strong> Crossing my fingers for a safe flight! (Though legally this will never occur)
            </p>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Future Enhancements</h2>
            <ul class="achievements-list">
                <li>Obstacle detection and avoidance during approach</li>
                <li>Emergency landing site selection when runway unavailable</li>
                <li>Full autonomous flight including takeoff, navigation, and landing</li>
            </ul>
        </div>
        
        <div class="content-section">
            <h2 class="section-title">Broader Applications</h2>
            <p class="section-text">
                I intend for this project to serve as a stepping stone to a future larger project that could assist GA pilots landing on unfinished runways. Another potential future project is to use this visual guidance technology to create a glider able to autonomously loiter.
            </p>
        </div>
    </div>
</body>
</html>
